{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e510a32-54e0-4d7e-a6aa-311b0fc0c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross-Validation Scores for RF:  [0.86538462 0.71153846 0.76923077 0.71153846 0.75       0.75\n",
      " 0.76470588 0.58823529 0.7254902  0.66666667]\n",
      "Mean CV Score:  0.7302790346907995\n",
      "Accuracy on the Test Set:  0.7131782945736435\n",
      "Missing values in 'MI_cat': 109818\n",
      "Missing Count: 109818, Predicted Count: 109818\n",
      "Predictions saved to Nairobi_MIcat_with_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3112/2033268980.py:75: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  ingestion_df['latitude'] = City_MIcat.geometry.centroid.y\n",
      "/tmp/ipykernel_3112/2033268980.py:76: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  ingestion_df['longitude'] = City_MIcat.geometry.centroid.x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion data saved to Nairobi_MIcat_ingestion_.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the GeoPackage file\n",
    "City_MIcat = gpd.read_file('Nairobi_Covariates_MIcat.gpkg')\n",
    "\n",
    "# Convert from Mollweide (ESRI:54009) to WGS84 (EPSG:4326)\n",
    "City_MIcat = City_MIcat.to_crs(epsg=4326)\n",
    "\n",
    "# Convert to a pandas DataFrame without the geometry column\n",
    "City_MIcat_df = pd.DataFrame(City_MIcat.drop(columns='geometry'))\n",
    "\n",
    "# Replace NaN with 0 in population columns\n",
    "City_MIcat_df['Pop_stddev'].fillna(0, inplace=True)\n",
    "City_MIcat_df['Pop_mean'].fillna(0, inplace=True)\n",
    "\n",
    "# Map categorical values to integers\n",
    "label_map = {'Low': 0, 'Med': 1, 'High': 2}\n",
    "City_MIcat_df['MI_cat'] = City_MIcat_df['MI_cat'].map(label_map)\n",
    "\n",
    "# Separate the data into training and prediction sets\n",
    "train_df = City_MIcat_df[City_MIcat_df['MI_cat'].notna()]  # Data with MI_cat values (0, 1, 2)\n",
    "predict_df = City_MIcat_df[City_MIcat_df['MI_cat'].isna()]  # Data with MI_cat as NaN\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = ['SDS_bin', 'roadlength', 'Pop_mean', 'Pop_stddev', 'ISL_bin', 'Intersections', 'Distance_mean']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df[feature_columns], train_df['MI_cat'].astype(int), test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_features='sqrt', oob_score=True, n_jobs=-1)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Perform 10-Fold Cross validation\n",
    "cv_scores_rf = cross_val_score(rf, x_train, y_train, cv=10, n_jobs=-1)\n",
    "print(\"10-Fold Cross-Validation Scores for RF: \", cv_scores_rf)\n",
    "print(\"Mean CV Score: \", np.mean(cv_scores_rf))\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy = accuracy_score(y_test, rf.predict(x_test))\n",
    "print(\"Accuracy on the Test Set: \", test_accuracy)\n",
    "\n",
    "# Check if there are any missing values in 'MI_cat'\n",
    "missing_count = City_MIcat_df['MI_cat'].isna().sum()\n",
    "print(f\"Missing values in 'MI_cat': {missing_count}\")\n",
    "\n",
    "if missing_count > 0:\n",
    "    # Prepare x_predict using the same features as x_train\n",
    "    x_predict = City_MIcat_df.loc[City_MIcat_df['MI_cat'].isna(), feature_columns]\n",
    "\n",
    "    # Ensure x_predict is not empty\n",
    "    if not x_predict.empty:\n",
    "        # Predict the missing values\n",
    "        predicted_values = rf.predict(x_predict)\n",
    "\n",
    "        # Check the lengths to ensure they match\n",
    "        predicted_count = len(predicted_values)\n",
    "        print(f\"Missing Count: {missing_count}, Predicted Count: {predicted_count}\")\n",
    "\n",
    "        # Assign the predicted values back to the original DataFrame\n",
    "        City_MIcat_df.loc[City_MIcat_df['MI_cat'].isna(), 'MI_cat'] = predicted_values\n",
    "\n",
    "        # Save the updated DataFrame with predictions\n",
    "        output_file_predictions = 'Nairobi_MIcat_with_predictions.csv'\n",
    "        City_MIcat_df.to_csv(output_file_predictions, index=False)\n",
    "        print(f\"Predictions saved to {output_file_predictions}\")\n",
    "\n",
    "        # Prepare the ingestion CSV with the required columns\n",
    "        ingestion_df = City_MIcat_df.copy()\n",
    "        ingestion_df['latitude'] = City_MIcat.geometry.centroid.y\n",
    "        ingestion_df['longitude'] = City_MIcat.geometry.centroid.x\n",
    "        ingestion_df['lat_min'] = City_MIcat.geometry.bounds['miny']\n",
    "        ingestion_df['lat_max'] = City_MIcat.geometry.bounds['maxy']\n",
    "        ingestion_df['lon_min'] = City_MIcat.geometry.bounds['minx']\n",
    "        ingestion_df['lon_max'] = City_MIcat.geometry.bounds['maxx']\n",
    "        ingestion_df['result'] = ingestion_df['MI_cat']  # Ensure this column is either 0, 1, or 2\n",
    "\n",
    "        # Select only the required columns\n",
    "        ingestion_df = ingestion_df[['latitude', 'longitude', 'lat_min', 'lat_max', 'lon_min', 'lon_max', 'result']]\n",
    "\n",
    "        # Save the ingestion CSV\n",
    "        output_file_ingestion = 'Nairobi_MIcat_ingestion_.csv'\n",
    "        ingestion_df.to_csv(output_file_ingestion, index=False)\n",
    "        print(f\"Ingestion data saved to {output_file_ingestion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869446a-c604-4d34-93bd-10e593485193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
